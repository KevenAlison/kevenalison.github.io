= PDI-2023.2
Repositório para arquivo de práticas e projetos relacionados à disciplina de Processamento Digital de Imagens.
Discente: link:https://KevenAlison.github.io[Keven Alison]

== UNIDADE 1

== Prática 1 - REGIONS

Com base no código `exemplos/pixels.cpp`, foi implementado um código que consiste em pegar os pontos definidos pelo usuário na entrada e transformar a região retangular definida por esses dois pontos em uma região negativa. Para isso, foi implementado um `for` que varre os pixels definidos pela região e define a cor de cada pixel através da função `image.at<uchar>`. Para a implementação, a imagem foi definida em grayscale para definir a cor máxima como 255, obtendo a cor negativa através da subtração desse valor pelo valor do pixel em grayscale.

[source,c++]
----
cout << "Cordenada x1: "<<endl;
cin >> px1;
cout << "Cordenada y1: "<<endl;
cin >> py1;
cout << "Cordenada x2: "<<endl;
cin >> px2;
cout << "Cordenada y2: "<<endl;
cin >> py2;

if(px1!=px2 && py1!=py2 &&px1>=0 && px2<=image.rows && py1>=0 && py2<=image.rows){
  for(int i=px1;i<px2;i++){
    for(int j=py1;j<py2;j++){
      image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
    }
  }
}
----

[#p1.1.PNG]
.Figura Original
image::/imgs/p1.1.PNG[Imagem 1]

[#p122.2.PNG]
.Figura Negativa
image::/imgs/p1.2.PNG[Imagem 2]

== Prática 2 - TROCAR REGIÕES

A segunda prática tem como objetivo dividir a imagem original em 4 partes iguais e inverter o quadrante destas partes. Para isso, foram utilizados recursos da classe `Mat`, como a função `rect()`, que facilitou armazenar cada pedaço da imagem em uma variável para posteriormente ser utilizada na imagem final, através da função `copyTo()`.

[source,c++]
----
// São definidas as 4 divisões da foto, resultando em 4 imagens, cada uma com uma parte retângular
Mat part1 = image(Rect(0,0,image.rows/2,image.cols/2));
Mat part2 = image(Rect(image.rows/2,0,image.rows/2,image.cols/2));
Mat part3 = image(Rect(0,image.cols/2,image.rows/2,image.cols/2));
Mat part4 = image(Rect(image.rows/2,image.cols/2,image.rows/2,image.cols/2));

part1.copyTo(img_embaralhada(Rect(image.rows/2,image.cols/2,image.rows/2,image.cols/2)));
part2.copyTo(img_embaralhada(Rect(0,image.cols/2,image.rows/2,image.cols/2)));
part3.copyTo(img_embaralhada(Rect(image.rows/2,0,image.rows/2,image.cols/2)));
part4.copyTo(img_embaralhada(Rect(0,0,image.rows/2,image.cols/2)));
----

[#p12.1.PNG]
.Imagem Original
image::/imgs/p1.1.PNG[Imagem 3]

[#P2.1.PNG]
.Imagem com regiões trocadas
image::/imgs/P2.1.PNG[Imagem 4]

== Prática 3 - ESTEGANOGRAFIA

Em resumo, a esteganografia se baseia em "criptografar" uma imagem dentro de outra, de forma que apenas uma delas fique visível. A técnica utilizada na disciplina, vista no exemplo `esteg-encode.cpp`, se baseia em codificar as imagens a partir da manipulação do conteúdo presente nos pixels da imagem, a partir da ordem de significância. Dada essa introdução, foi proposta a decodificação da seguinte figura, que possui uma imagem oculta entre seus pixels.

[#cod_img.PNG]
.Imagem Original Codificada
image::/imgs/cod_img.PNG[Imagem 5]

Para a figura em questão, após montado o código e realizando alguns testes, percebeu-se que a figura oculta estava presente nos 3 bits menos significativos da imagem codificada. Dessa forma, a figura original é representada pelos 5 bits mais significativos, e a figura escondida é representada pelos 3 bits menos significativos.

[source,c++]
----
img_decoded = img_encoded.clone();

for (int i = 0; i < img_encoded.rows; i++) {
    for (int j = 0; j < img_encoded.cols; j++) {
        val_encoded = img_encoded.at<Vec3b>(i, j);

        val_decoded[0] = val_encoded[0] << (8-nbits);
        val_decoded[1] = val_encoded[1] << (8-nbits);
        val_decoded[2] = val_encoded[2] << (8-nbits);

        img_decoded.at<Vec3b>(i, j) = val_decoded;
    }
}
----

[#cod_img2.PNG]
.Imagem Original Codificada
image::/imgs/cod_img.PNG[Imagem 6]

[#decod_img.PNG]
.Imagem Decodificada
image::/imgs/decod_img.PNG[Imagem 7]

== Prática 4 - PREENCHIMENTO DE REGIÕES

Para este exercício, temos uma imagem com objetos dispostos no espaço. Nosso objetivo é identificar as "bolhas", realizando a contagem de quantas têm buracos e quantas não têm.

[#bubble1.PNG]
.Imagem Original
image::/imgs/bubble1.PNG[Imagem 8]

Vendo a imagem, o primeiro desafio é remover as bolhas que tocam a borda da imagem, pois não dá para saber com certeza se há ou não buracos nelas, já que não conseguimos ver seu corpo completo. Para eliminar esses objetos, foi construída uma lógica que varre as posições correspondentes à borda da imagem, caçando objetos que estejam nesse limite e preenchendo com a cor de fundo, para dar a impressão de que foram retirados.


[source,c++]
----
width = image.cols;
height = image.rows;
p.x = 0;
p.y = 0;
n_objremovido = 0;
for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
         if(image.at<uchar>(i,j) == 255 && (i == 0 || i == height-1 || j == 0 || j == width-1)){
	    n_objremovido++;
            p.x = j;
            p.y = i;
            floodFill(image, p, 0);
        }
    }
}
image_sborda = image.clone();
----

[#bubble2.PNG]
.Imagem Sem Bolhas na Borda
image::/imgs/bubble2.PNG[Imagem 9]

Em seguida, é utilizado o algoritmo Flood Fill para identificar e contar a quantidade de elementos na imagem.

[source,c++]
----
n_objects = 0;
for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
        if (image.at<uchar>(i, j) == 255) {
            // Achou um objeto
            n_objects++;
            p.x = j;
            p.y = i;
            // Preenche o objeto com o contador
            floodFill(image, p, n_objects);
        }
    }
}
p.x = 0;
p.y = 0;
floodFill(image, p, 255);

int buracos = 0;
for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
        if (image.at<uchar>(i, j) == 0) {
            buracos++;
            p.x = j;
            p.y = i;
            floodFill(image, p, buracos);
        }
    }
}
----

[#bubble3.PNG]
.Imagem com Bolhas Preenchidas
image::/imgs/bubble3.PNG[Imagem 10]

== Prática 5 - HISTOGRAMA & EQUALIZAÇÃO

A prática a seguir tem como objetivo principal a implementação de um programa que utiliza como base a webcam para capturar imagens e realizar a equalização do histograma. No meu caso, não foi possível utilizar a webcam devido a algumas limitações do meu ambiente, então utilizei a mesma imagem base utilizada nos exemplos anteriores. O programa teve como base o exemplo histogram.cpp e basicamente extrai o histograma da imagem original em escala de cinza e, em seguida, realiza a equalização, criando um novo histograma para a imagem equalizada. A equalização do histograma é facilmente realizada através da função equalizeHist.

[source,c++]
----
int histw = nbins, histh = nbins / 2;
Mat histImgegray(histh, histw, CV_8UC1, Scalar(0));
Mat histImgequalizado(histh, histw, CV_8UC1, Scalar(0));

while (1) {
    image.copyTo(gray);

    // Calculando histograma da imagem em escala de cinza original
    calcHist(&gray, 1, 0, Mat(), histgray, 1,
             &nbins, &histrange,
             uniform, accumulate);

    normalize(histgray, histgray, 0, histImgegray.rows, cv::NORM_MINMAX, -1, Mat());

    histImgegray.setTo(Scalar(0));

    for (int i = 0; i < nbins; i++) {
        line(histImgegray,
             Point(i, histh),
             Point(i, histh - cvRound(histgray.at<float>(i))),
             Scalar(255), 1, 8, 0);
    }

    histImgegray.copyTo(gray(Rect(0, 0, nbins, histh)));

    imshow("Grayscale", gray);

    // Equalizar histograma
    equalizeHist(image, iequalizado);

    // Calculando histograma da imagem equalizada
    calcHist(&iequalizado, 1, 0, Mat(), histequalizado, 1, &nbins, &histrange, uniform, accumulate);

    // Normalizando
    normalize(histequalizado, histequalizado, 0, histImgequalizado.rows, NORM_MINMAX, -1, Mat());

    histImgequalizado.setTo(Scalar(0));

    for (int i = 0; i < nbins; i++) {
        line(histImgequalizado,
            Point(i, histh),
            Point(i, histh - cvRound(histequalizado.at<float>(i))),
            Scalar(255, 255, 255), 1, 8, 0);
    }

    histImgequalizado.copyTo(iequalizado(Rect(0, 0, nbins, histh)));

    imshow("Imagem Equalizada", iequalizado);

    key = waitKey(30);
    if (key == 27) break;
}
----

Com o código aplicado, temos o seguinte resultado de saída para a imagem ghibli.png:

[#histo_grayscale.PNG]
.Histograma Imagem Original
image::/imgs/histo_grayscale.PNG[Imagem 11]

[#histo_equalize.PNG]
.Histograma Imagem Equalizada
image::/imgs/histo_equalize.PNG[Imagem 12]

== Prática 6 - FILTROS LAPLACIANO E LAPLACIANO DO GAUSSIANO

Para esta prática, foi utilizado como referência o código filtroespacial.cpp, cuja funcionalidade conta com diversos filtros de imagem. O objetivo era implementar um filtro Laplaciano do Gaussiano e compará-lo com o filtro Laplaciano, que já estava implementado no código original.

[source,c++]
----

#include <iostream>
#include <opencv2/opencv.hpp>

void printmask(cv::Mat &m) {
  for (int i = 0; i < m.size().height; i++) {
    for (int j = 0; j < m.size().width; j++) {
      std::cout << m.at<float>(i, j) << ",";
    }
    std::cout << "\n";
  }
}

int main(int, char ** argv) {
  cv::Mat image, framegray, frame32f, frameFiltered;
  float media[] = {0.1111, 0.1111, 0.1111, 0.1111, 0.1111,
                   0.1111, 0.1111, 0.1111, 0.1111};
  float gauss[] = {0.0625, 0.125,  0.0625, 0.125, 0.25,
                   0.125,  0.0625, 0.125,  0.0625};
  float horizontal[] = {-1, 0, 1, -2, 0, 2, -1, 0, 1};
  float vertical[] = {-1, -2, -1, 0, 0, 0, 1, 2, 1};
  float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
  float boost[] = {0, -1, 0, -1, 5.2, -1, 0, -1, 0};
  float laplgauss [] ={0,0,-1,0,0,0,-1,-2,-1,0,-1,-2,16,-2,-1,
                      0,-1,-2,-1,0,0,0,-1,0,0};
  cv::Mat mask(3, 3, CV_32F), mask_scale;
  cv::Mat result;
  int absolut;
  char key;

  image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE); // Carregar a imagem em escala de cinza
  if (!image.data) {
    std::cout << "Erro ao abrir a imagem" << std::endl;
    return -1;
  }

  cv::namedWindow("filtro aplicado", cv::WINDOW_NORMAL);
  cv::namedWindow("original", cv::WINDOW_NORMAL);

  mask = cv::Mat(3, 3, CV_32F, media); // Inicializar a máscara
  absolut = 1; // Calcula o valor absoluto da imagem

  for (;;) {
    cv::imshow("original", image);
    image.convertTo(frame32f, CV_32F);
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask, cv::Point(1, 1), 0);
    if (absolut) {
      frameFiltered = cv::abs(frameFiltered);
    }

    frameFiltered.convertTo(result, CV_8U);

    cv::imshow("filtro aplicado", result);

    key = (char)cv::waitKey(10);
    if (key == 27) break; // Tecla Esc pressionada!
    switch (key) {
      case 'a':
        absolut = !absolut;
        break;
      case 'm':
        mask = cv::Mat(3, 3, CV_32F, media);
        printmask(mask);
        break;
      case 'g':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        printmask(mask);
        break;
      case 'h':
        mask = cv::Mat(3, 3, CV_32F, horizontal);
        printmask(mask);
        break;
      case 'v':
        mask = cv::Mat(3, 3, CV_32F, vertical);
        printmask(mask);
        break;
      case 'l':
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        printmask(mask);
        break;
        case 'p':
        mask = cv::Mat(5, 5, CV_32F, laplgauss);
        printmask(mask);
        break;
      case 'b':
        mask = cv::Mat(3, 3, CV_32F, boost);
        break;
      default:
        break;
    }
  }
  return 0;
}
----

Como resultado, é perceptível que o filtro Laplaciano do Gaussiano possui maior atenuação nas regiões de contorno da imagem, intensificando as bordas em comparação ao filtro gaussiano mais simples. Isso ocorre porque esse filtro funciona primeiro suavizando a imagem através do filtro gaussiano, tornando as bordas mais nítidas e proeminentes devido ao efeito de suavização, e depois aplicando o Laplaciano, que detecta as bordas com mais precisão devido ao efeito do gaussiano.

[#mean_filter.PNG]
.Filtro Gaussiano
image::/imgs/mean_filter.PNG[Imagem 13]

[#lap_filter.PNG]
.Filtro Laplaciano
image::/imgs/lap_filter.PNG[Imagem 14] 

[#lapgauss_filter.PNG]
.Filtro Laplaciano do Gaussiano
image::/imgs/lapgauss_filter.PNG[Imagem 15]

== Prática 6 - ALGORITMO TILTSHIFT
Esta prática tem como objetivo utilizar o código 'addweighted.cpp' como referência para implementação de um programa tiltshift.cpp que é capaz de definir uma região na imagem para ser borrada, de forma que essa região seja controlada pelo usuário na interface gráfica atravéz de 'trackbars'.
O programa original já conta com duas trackbars, porém não são úteis para nossa aplicação na forma que estão implementadas. Sendo assim foram criadas 3 funções de implementação de trackbar do tipo slider para altura, deslocamento e decaimento.

[source,c++]
----

#include <iostream>
#include <opencv2/opencv.hpp>

int l1 = -100;
int l2 = 50;
int d = 6;
int centro = 100;
int altura = 0;
int largura = 0;
int slider_altura = 0;
int slider_altura_max = 100;
int slider_decaimento = 0;
int slider_decaimento_max = 100;
int slider_deslocamento = 0;
int slider_deslocamento_max = 100;

cv::Mat imagem, imagem_borrada, ponderada, ponderada_negativa, resultado;

void addEffect() {
    altura = imagem.rows;
    largura = imagem.cols;
    centro = slider_deslocamento * altura / 100;

    for (int i = 0; i < altura; i++) {
        double fx = 0.0;
        if (d != 0) {
            fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
        } else {
            fx = -0.5 * (tanh((i - centro + l1) / 0.01) - tanh((i - centro + l2) / 0.01));
        }

        for (int j = 0; j < largura; j++) {
            ponderada.at<cv::Vec3d>(i, j) = cv::Vec3d(fx, fx, fx);
            ponderada_negativa.at<cv::Vec3d>(i, j) = cv::Vec3d(1.0 - fx, 1.0 - fx, 1.0 - fx);
        }
    }

    cv::Mat res1, res2;
    imagem.convertTo(imagem, CV_64FC3);
    imagem_borrada.convertTo(imagem_borrada, CV_64FC3);

    res1 = imagem.mul(ponderada);
    res2 = imagem_borrada.mul(ponderada_negativa);

    resultado = res1 + res2;

    resultado.convertTo(resultado, CV_8UC3);

    cv::imshow("tiltshift", resultado);

    // Salvar a imagem resultante em um arquivo
    cv::imwrite("resultado_tiltshift.png", resultado);
}

void on_trackbar_deslocamento(int val, void* userdata) {
    slider_deslocamento = val;
    addEffect();
}

void on_trackbar_altura(int val, void* userdata) {
    slider_altura = val;
    int alt = altura * slider_altura / 100;
    l1 = -alt / 2;
    l2 = alt / 2;
    addEffect();
}

void on_trackbar_decaimento(int val, void* userdata) {
    slider_decaimento = val;
    d = slider_decaimento;
    addEffect();
}

int main(int argc, char** argv) {
    imagem = cv::imread("ghibli.png", cv::IMREAD_COLOR);

    if (imagem.empty()) {
        std::cout << "Erro ao carregar a imagem." << std::endl;
        return -1;
    }

    cv::resize(imagem, imagem, cv::Size(800, 600));

    cv::Mat media = cv::Mat::ones(7, 7, CV_64F) / (7.0 * 7.0);
    cv::filter2D(imagem, imagem_borrada, -1, media);

    ponderada = cv::Mat(imagem.rows, imagem.cols, CV_64FC3);
    ponderada_negativa = cv::Mat(imagem.rows, imagem.cols, CV_64FC3);
    resultado = cv::Mat(imagem.rows, imagem.cols, CV_64FC3);

    // Valores iniciais dos sliders
    slider_altura = 0;
    slider_decaimento = 0;
    slider_deslocamento = 0;

    cv::namedWindow("tiltshift", cv::WINDOW_AUTOSIZE);

    cv::createTrackbar("Altura x 100", "tiltshift", &slider_altura, slider_altura_max, on_trackbar_altura, nullptr);
    cv::createTrackbar("Decaimento x 100", "tiltshift", &slider_decaimento, slider_decaimento_max, on_trackbar_decaimento, nullptr);
    cv::createTrackbar("Deslocamento x 100", "tiltshift", &slider_deslocamento, slider_deslocamento_max, on_trackbar_deslocamento, nullptr);

    addEffect();

    cv::waitKey(0);
    return 0;
}

----

[#tiltshift.PNG]
.Imagem com slidebars
image::/imgs/tiltshift.PNG[Imagem 16]

== UNIDADE 2

== Prática 1 - ALGORITMO DE CLUSTERIZAÇÃO
Para essa prática utilizouj-se o programa 'kmeans,cpp' com algumas alterações para analisarmos o resultado da filtragem. O programa em questão tem como parâmetro nRodadas=1 e gera centros de forma aleatória, resultando em uma filtragem diferente à cada execução, em teoria.

[source,c++]
----

#include <opencv2/opencv.hpp>
#include <cstdlib>

using namespace cv;
using namespace std;

int main(int argc, char** argv) {
    if (argc != 2) {
        cout << "Usage: " << argv[0] << " <image_path>" << endl;
        return -1;
    }

    int nClusters = 8, nRodadas = 1;
    Mat rotulos, centros;

    Mat img = imread(argv[1], IMREAD_COLOR);

    if (img.empty()) {
        cout << "Erro ao ler a imagem." << endl;
        return -1;
    }

    Mat samples(img.rows * img.cols, 3, CV_32F);
    for (int y = 0; y < img.rows; y++) {
        for (int x = 0; x < img.cols; x++) {
            for (int z = 0; z < 3; z++) {
                samples.at<float>(y + x * img.rows, z) = img.at<Vec3b>(y, x)[z];
            }
        }
    }

    // Verifique o número de elementos e clusters antes de chamar kmeans
    cout << "Number of elements (N): " << samples.rows << endl;
    cout << "Number of clusters (K): " << nClusters << endl;

    if (samples.rows > 0 && nClusters <= samples.rows) {
        kmeans(samples,
               nClusters,
               rotulos,
               TermCriteria(TermCriteria::MAX_ITER | TermCriteria::EPS, 10000, 0.0001),
               nRodadas,
               KMEANS_RANDOM_CENTERS,
               centros);
    } else {
        cout << "Error: Number of clusters should be less than or equal to the number of elements." << endl;
        return -1;
    }

    Mat rotulada(img.size(), img.type());
    for (int y = 0; y < img.rows; y++) {
        for (int x = 0; x < img.cols; x++) {
            int indice = rotulos.at<int>(y + x * img.rows, 0);
            rotulada.at<Vec3b>(y, x)[0] = (uchar)centros.at<float>(indice, 0);
            rotulada.at<Vec3b>(y, x)[1] = (uchar)centros.at<float>(indice, 1);
            rotulada.at<Vec3b>(y, x)[2] = (uchar)centros.at<float>(indice, 2);
        }
    }

    imshow("Imagem original:", img);
    imshow("Imagem clusterizada: ", rotulada);

    waitKey();

    return 0;
}

O código em questão foi executado 10 vezes, gerando os seguintes resultados:
----
[#mononoke.png]
.Imagem com slidebars
image::/imgs/mononoke.png[Imagem 16]

[#mononokegif.gif]
.Imagem com slidebars
image::/imgs/mononoke.gif[Imagem 16]

É perceptível que não há grandes mudanças para a imagem em questão, além de alguns detalhes sutis que variam em certas execuções. Isso pode estar ocorrendo devido ao baixo numero de rodadas, que pode vir a afetar a estabilidade dos resultados.


== Prática 2 - DIGITOS
O problema em questão indica o uso do programa 'morfologia.cpp' como base para a criação de um sistema que faça o reconhecimento e preenchimento de caracteres numéricos de segmento em imagens, dada a dificuldade que softwares de reconhecimento podem ter ao tentar identificar os números nesse padrão. 
Para resolver esse problema o código foi desenvolvido com base na crianção de formas retangulares para preencher os espaços entre os digitos através da aplicação de uma erosão seguida por uma dilatação, usando um elemento estruturante retangular de tamanho 4x15 para gerar um resultado coerente com as proporções da imagem. 

[source,c++]
----

#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main () {

    Mat image_original, resultado, element;

    image_original = imread (argv[1], IMREAD_UNCHANGED);

    if (image_original.empty()) {
        cout << "Erro ao carregar a imagem de referência." << endl;
        return -1;
    }

    //element = getStructuringElement(MORPH_RECT, Size(3,3));
    //element = getStructuringElement(MORPH_RECT, Size(5,10));
    //element = getStructuringElement(MORPH_RECT, Size(4,10));
    element = getStructuringElement(MORPH_RECT, Size(4,15));
    morphologyEx (image_original, resultado, MORPH_OPEN, element);
    imshow ("Original:", image_original);
    imshow ("Resultado:", resultado);
    waitKey ();

    return 0;
}


----

[#digitos.PNG]
.Comparação do resultado
image::/imgs/digitos.png[Imagem 16]